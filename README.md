# ML Arena Pong 2024 Competition

Welcome to ML Arena Pong 2024, a multiplayer reinforcement learning competition where you'll develop intelligent agents to master the classic game of Pong with a competitive twist! 

## ğŸ”— Quick Links

- [Competition Page](https://ml-arena.com/viewcompetition/3)
- [PettingZoo Pong Environment](https://pettingzoo.farama.org/environments/atari/pong/)
- [ML Arena Platform](https://ml-arena.com)

## ğŸ® Competition Overview

Compete against other AI agents in a multiplayer Pong environment where your agent needs to learn optimal strategies for both offensive and defensive play. The competition uses the PettingZoo Pong environment and features:

- 2-player sequential Pong
- ELO ranking system
- CPU, RAM, Memory constraints
- Support for PyTorch, JAX, and TensorFlow frameworks

## ğŸ“¦ Repository Structure

```
ml-arena-pong2024/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pong/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ environment.py    # Core Pong environment wrapper
â”‚   â”‚   â”œâ”€â”€ renderer.py       # Visualization utilities
â”‚   â”‚   â””â”€â”€ types.py         # Type definitions
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ evaluate.py      # Local evaluation tools
â”‚       â””â”€â”€ replay.py        # Replay visualization
â”œâ”€â”€ kit/                    # Python starter kit
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ agent.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ random_agent.py
â”‚   â”œâ”€â”€ rule_based_agent.py
â”‚   â””â”€â”€ simple_dqn_agent.py
â””â”€â”€ tests/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_environment.py
    â””â”€â”€ test_agents.py
```

## ğŸš€ Getting Started

### Installation

```bash
# Create and activate environment
conda create -n "ml-arena-pong" python=3.10
conda activate ml-arena-pong

# Clone repository
git clone https://github.com/ml-arena/pong2024.git
cd pong2024

# Install package and dependencies
pip install -e .
pip install "pettingzoo[atari]"  # Install PettingZoo with Atari support
```

### Verify Installation

```bash
# Run a test match between two random agents
ml-arena-pong examples/random_agent.py examples/random_agent.py --output replay.json

# Visualize the replay
ml-arena-pong-vis replay.json
```

## ğŸ›  Python Starter Kit

The Python starter kit provides everything you need to get started:

- Basic agent implementation
- Environment interaction examples
- Local testing setup
- Support for PyTorch, JAX, or TensorFlow

Check out [kit/README.md](kit/README.md) for detailed instructions.

## ğŸ“Š Local Evaluation

Test your agent locally:

```bash
# Run a single match
ml-arena-pong path/to/your/agent.py examples/random_agent.py

# Run multiple evaluation matches
ml-arena-pong-evaluate path/to/your/agent.py --num-games 100 --save-stats

# Profile agent performance
ml-arena-pong-profile path/to/your/agent.py --timeout 100
```

## ğŸ“ Competition Rules

### Match Format
- 3000 steps match
- Points scored through successful paddle hits and opponent misses

### Agent Requirements
- Must respond within 50ms per step
- Maximum 1GB memory usage
- Supports partially observable state
- Must be compatible with runtime provided

### Evaluation Criteria
1. Win/loss/draw elo in tournament matches

## ğŸ“… Important Dates

- **Competition Start**: January 22, 2025
- **Final Submission Deadline**: April 1, 2025

## ğŸ“– Documentation

- [Environment Guide](docs/environment.md)
- [Agent Development](docs/agent.md)
- [Submission Guide](docs/submission.md)

## ğŸ’¬ Community

- [Discord Server](https://discord.gg/ml-arena)
- [GitHub Discussions](https://github.com/ml-arena/pong2024/discussions)

## ğŸ“Š Leaderboard

Current leaderboard available at: [ML Arena Pong 2024 Leaderboard](https://ml-arena.com/viewcompetition/3)

## ğŸ¤ Contributing

Contributions are welcome! Please check our [Contributing Guidelines](CONTRIBUTING.md).

## ğŸ™ Acknowledgments

- Competition infrastructure powered by ML Arena
- Environment provided by PettingZoo
- Special thanks to our community contributors